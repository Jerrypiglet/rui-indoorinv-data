data = {
    dataset_root = data/openrooms_public
    xml_root = data/openrooms_public
    # xml_file = test.xml # relative to xml_root
}

scene_params_dict = {
    shape_file = "" # relative to dataset_root
    frame_id_list = []
    invalid_frame_id_list = []
    scene_radiance_scale = 1.0
    mitsuba_version = "3.0.0"
    axis_up = "y+"
    pose_file = "cam.txt"
    # pose_file = "json-transforms.json" # json file will be generated in Blender rendering
    # pose_file = "Blender-train.npy"

    indexing_based = 1 # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! major difference to the re-rendered 200 pose version
    openrooms_version = "public" # 'public' or 'public_re_0203'
    }

im_params_dict = {
    im_H_load = 480
    im_W_load = 640
    im_H_resize = 480
    im_W_resize = 640
    spp = 4096
    hdr_radiance_scale = 0.05 # for scaling HDR images in export
    }

modality_filename_dict = {
    # im_hdr = im_hdr/im_%d.hdr
    # im_sdr = im_sdr/im_%d.png
    # albedo = albedo/imbaseColor_%d.png
    # roughness = roughness/imroughness_%d.png
    # depth = depth/imdepth_%d.dat
    # normal = normal/imnormal_%d.png
    # seg = mask/immask_%d.png
    # semseg = semseg/imsemLabel_%d.npy
    # matseg = matseg/imcadmatobj_%d.dat
    im_hdr = im_%d.hdr
    im_sdr = [/data/ruizhu/OR-pngs, im_%d.png]
    albedo = imbaseColor_%d.png
    roughness = imroughness_%d.png
    depth = imdepth_%d.dat
    normal = imnormal_%d.png
    seg = immask_%d.png
    semseg = imsemLabel_%d.npy
    matseg = imcadmatobj_%d.dat
}

cam_params_dict = {
    near = 0.1
    far = 10.0
    sampleNum = 3
    
    # == params for sample camera poses
    heightMin = 0.5 # camera height min
    heightMax = 2.2 # camera height max
    distMin = 0.5 # to wall distance min
    distMax = 4.5 # to wall distance max
    thetaMin = -60 # theta min: pitch angle; up+ 
    thetaMax = 60 # theta max: pitch angle; up+
    phiMin = -60 # yaw angle minconfs/indoor_synthetic.conf
    phiMax = 60 # yaw angle max
    distRaysMin = 0.3 # min dist of all camera rays to the scene; [!!!] set to -1 to disable checking
    distRaysMedianMin = 0.6 # median dist of all camera rays to the scene; [!!!] set to -1 to disable checking
}

lighting_params_dict = {
    SG_num = 12

    # how many envmaps of one frame
    env_row = 120
    env_col = 160 # resolution to load; FIXED
    env_downsample_rate = 20 # (120, 160) -> (6, 8)
    
    # how many pixels in one envmap
    # 'env_height': 2, 'env_width': 4, 
    # 'env_height': 8, 'env_width': 16, 
    # 'env_height': 128, 'env_width': 256, 
    env_height = 16
    env_width = 32
    if_convert_lighting_SG_to_global = True
    if_use_mi_geometry = True
    if_direct_lighting = False # if load direct lighting envmaps and SGs inetad of total lighting
}

BRDF_params_dict = {

}

mi_params_dict = {
    debug_render_test_image = False # [DEBUG][slow] True: to render an image with first camera, usig Mitsuba: images/demo_mitsuba_render.png
    debug_dump_mesh = False # [DEBUG] True: to dump all object meshes to mitsuba/meshes_dump; load all .ply files into MeshLab to view the entire scene: images/demo_mitsuba_dump_meshes.png
    if_sample_rays_pts = True # True: to sample camera rays and intersection pts given input mesh and camera poses
    if_get_segs = True # [depend on if_sample_rays_pts] True: to generate segs similar to those in openroomsScene2D.load_seg()
    if_mi_scene_from_xml = False # priority to load mitsuba scene from shapes (obj or tsdf) instead of from xml

}

shape_params_dict = {
    tsdf_file = fused_tsdf.ply # 'test_files/tmp_tsdf.ply', 
    # tsdf_file = fused_tsdf.obj # 'test_files/tmp_tsdf.ply', 

    if_load_obj_mesh = True # set to False to not load meshes for objs (furniture) to save time
    if_load_emitter_mesh = True  # default True: to load emitter meshes, because not too many emitters

    if_sample_pts_on_mesh = False  # default True: sample points on each shape -> self.sample_pts_list
    sample_mesh_ratio = 0.1 # target num of VERTICES: len(vertices) * sample_mesh_ratio
    sample_mesh_min = 10
    sample_mesh_max = 100

    if_simplify_mesh = False # default True: simply triangles
    simplify_mesh_ratio = 0.1 # target num of FACES: len(faces) * simplify_mesh_ratio
    simplify_mesh_min = 100
    simplify_mesh_max = 1000
    if_remesh = True # False: images/demo_shapes_3D_kitchen_NO_remesh.png; True: images/demo_shapes_3D_kitchen_YES_remesh.png
    remesh_max_edge = 0.15
    
    if_dump_shape = False # True to dump fixed shape to obj file
    if_fix_watertight = False
}

emitter_params_dict={
    N_ambient_rep = 3SG-SkyGrd
    }
